{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9fbcdd",
   "metadata": {},
   "source": [
    "# Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf9e55",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
    "\n",
    "Your work will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
    "\n",
    "Additional points may be deducted if these requirements are not met:\n",
    "    \n",
    "* Comment your code;\n",
    "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own;\n",
    "* Try and minimize the use of the global namespace (meaning, keep things inside functions).\n",
    "\n",
    "Additional note:\n",
    "\n",
    "* You can complete this assignment using either your local machine or Google Colab. Your solution for this assignment should be able to run on the <span style=\"color:red\">FREE version</span> of Google Colab. If you find that you need to upgrade to the paid version, it indicates that there is an inefficiency in your code.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306ae3e",
   "metadata": {},
   "source": [
    "#### ``Objectives``\n",
    "1. Implement a Decision Forest for land cover classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaabb203",
   "metadata": {},
   "source": [
    "#### ``Motivation``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879a5bf",
   "metadata": {},
   "source": [
    "Land cover classification using machine learning (ML) techniques is important for several reasons, spanning environmental monitoring, resource management, urban planning, disaster response, and scientific research. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878526d8",
   "metadata": {},
   "source": [
    "#### ``Data``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8f95b",
   "metadata": {},
   "source": [
    "In this assignment, you will use the EuroSAT dataset, consisting of Sentinel-2 RGB satellite images of 10 classes with 27000 labeled and geo-referenced samples. \n",
    "\n",
    "The dataset is hosted by [TensorFlow Data Collections](https://www.tensorflow.org/datasets/catalog/eurosat). To avoid any data versioning issues, we have downloaded the data for you (please see below).\n",
    "\n",
    "`Download` link: [images + labels](https://drive.google.com/file/d/131GuYn092OlWKGopsT8arQoDreneU7SZ/view?usp=share_link). Once you unzip the file, you will see that the name of each subfolder represents the land cover classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abbfd7d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced1b2e",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) #used to supress the tf version warning. \n",
    "\n",
    "# FILL IN CODE HERE #\n",
    "DATA_PATH = \"./EuroSAT\" # replace with your path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796b743",
   "metadata": {},
   "source": [
    "^ make sure to replace DATA_PATH with the path to the directory where you saved the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1ca78",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59deaa1c",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 1 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53539c3d",
   "metadata": {},
   "source": [
    "Let's load the 2D images and their corresponding labels. Implement the <span style=\"color:chocolate\">load_data()</span> function below according to the following guidelines:\n",
    "- to read label and image names: use the <span style=\"color:chocolate\">os</span> library (in particular the <span style=\"color:chocolate\">os.listdir()</span> and <span style=\"color:chocolate\">os.path.join()</span> methods);\n",
    "- to load an image: use the <span style=\"color:chocolate\">load_image()</span> method (see list of imported libraries);\n",
    "- to transform images to arrays: use the <span style=\"color:chocolate\">img_to_array()</span> method (see list of imported libraries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbe97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_data):\n",
    "    '''Load 2D images and their corresponding labels\n",
    "    Parameters:\n",
    "    path_to_data (str): This is the path to data\n",
    "    \n",
    "    Returns:\n",
    "    images (np.ndarray): A numpy array of shape (N, 64, 64, 3)\n",
    "    labels (np.ndarray): A numpy array of shape (N)\n",
    "    \n",
    "    '''\n",
    "    ## load images and labels\n",
    "    # FILL IN CODE HERE #  \n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e44bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels. Print shapes\n",
    "\n",
    "images, labels = load_data(DATA_PATH)\n",
    "print(\"Shape of images \", images.shape)\n",
    "print(\"Shape of labels \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd6b9d",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99bede",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 2 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5d5db",
   "metadata": {},
   "source": [
    "Plot the land cover class distribution. Are the classes balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ae2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN CODE HERE # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147459fa",
   "metadata": {},
   "source": [
    "Comment on class balance: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d82423",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 3 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a534af",
   "metadata": {},
   "source": [
    "Inspect (print) one image from each class. What land classes do you think a Decision Tree classifier is more likely to confuse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f8920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f451c18f",
   "metadata": {},
   "source": [
    "Most confused land classes: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22fe304",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185af002",
   "metadata": {},
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82270e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder().fit(list(set(labels))) # fit on unique labels\n",
    "encoded_labels = encoder.transform(labels) # apply to labels array (will get labels from 0 to 9)\n",
    "encoded_labels_classes = list(encoder.classes_) # store mapping generated by the encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43016668",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 4 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e56c5",
   "metadata": {},
   "source": [
    "Create train, validation, and test data. Implement the <span style=\"color:chocolate\">split_data()</span> function below according to the following guidelines:\n",
    "- shuffle images and labels before spliting the data;\n",
    "- use a 60/20/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40daa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(images, labels, split):\n",
    "    '''Split data into train, validation and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    images  (np.ndarray): Images of shape (N, 64, 64, 3)\n",
    "    labels (np.ndarray): Labels of shape (N,)   \n",
    "    split (tuple): 3 values summing to 1 defining split of train, validation and test sets\n",
    "    \n",
    "    Returns:\n",
    "    X_train (np.ndarray): Train images of shape (N_train, 64, 64, 3)\n",
    "    y_train (np.ndarray): Train labels of shape (N_train,)\n",
    "    X_val (np.ndarray): Val images of shape (N_val, 64, 64, 3)\n",
    "    y_val (np.ndarray): Val labels of shape (N_val,)\n",
    "    X_test (np.ndarray): Test images of shape (N_test, 64, 64, 3)\n",
    "    y_test (np.ndarray): Test labels of shape (N_test,)\n",
    "    \n",
    "    '''\n",
    "    # NOTE: Each time you run this cell, you'll re-shuffle the data. The ordering will be the same due to the random seed generator \n",
    "    tf.random.set_seed(1234)\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    # shuffle data\n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    # create data splits\n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c42b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define splits\n",
    "split = (0.6, 0.2, 0.2)\n",
    "\n",
    "# create train, val, test sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(images, encoded_labels, split)\n",
    "\n",
    "# print shapes\n",
    "print('Shape of train images ', X_train.shape)\n",
    "print('Shape of train labels ', y_train.shape)\n",
    "\n",
    "print('Shape of val images ', X_val.shape)\n",
    "print('Shape of train labels ', y_val.shape)\n",
    "\n",
    "print('Shape of test images ', X_test.shape)\n",
    "print('Shape of test labels ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b5277",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 5 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f3a96",
   "metadata": {},
   "source": [
    "Perform image transformation and augmentation. \n",
    "\n",
    "<span style=\"color:green\"> Step 1: </span> Implement the <span style=\"color:chocolate\">data_preprocessing()</span> function below according to the following guidelines:\n",
    "\n",
    "- Applied on training set only: \n",
    "    - create additional copies of the training images by applying the following augmentation techniques to each image: adjust brightness by adding DELTA=0.3 to the pixel values, then adjust contrast to CONTRAST_FACTOR=3, then flip left right (Hint: use the methods available in the tf.image module);\n",
    "    - concatenate the augmented images to the original training images. Note that the train set should be double in size after data augmentation, i.e., 32400 images and labels;\n",
    "    \n",
    "    \n",
    "- Applied on training, validation, and test sets: normalize all pixel values by dividing by 255.0.\n",
    "    \n",
    "<span style=\"color:green\"> Step 2: </span> Comment on the importance of adding augmented images to training data (be sure to justify why you don't augment the validation and test sets as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(X, y, data_partition='train'):\n",
    "    '''Apply transformations and augmentations to training, validation, and test dat;\n",
    "    \n",
    "    Parameters:\n",
    "    X  (np.ndarray): Images of shape (N, 64, 64, 3)\n",
    "    y (np.ndarray): Labels of shape (N,)   \n",
    "    data_partition (str): \"train\"\n",
    "    \n",
    "    Returns:\n",
    "    X (np.ndarray): Preprocessed images of shape (N, 64, 64, 3)\n",
    "    y (np.ndarray): Labels of shape (N,)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    CONTRAST_FACTOR = 3\n",
    "    DELTA = 0.3\n",
    "    \n",
    "    # image augmentation on training data\n",
    "    if data_partition==\"train\":\n",
    "        # adjust brightness\n",
    "        X_augm = '' # FILL IN CODE HERE #\n",
    "\n",
    "        # adjust contrast\n",
    "        X_augm = '' # FILL IN CODE HERE #\n",
    "\n",
    "        # random flip\n",
    "        X_augm = '' # FILL IN CODE HERE #\n",
    "\n",
    "        # concatenate original X and augmented X_aug data\n",
    "        X = '' # FILL IN CODE HERE #\n",
    "\n",
    "        # concatenate y_train (note the label is preserved)\n",
    "        y_augm = y\n",
    "        y = tf.concat([y, y_augm],axis=0)\n",
    "\n",
    "        # shuffle X and y, i.e., shuffle two tensors in the same order\n",
    "        shuffle = tf.random.shuffle(tf.range(tf.shape(X)[0], dtype=tf.int32))\n",
    "        X = tf.gather(X, shuffle).numpy() # transform X back to numpy array instead of tensor\n",
    "        y = tf.gather(y, shuffle).numpy() # transform y back to numpy array instead of tensor\n",
    "        \n",
    "        \n",
    "    # rescale image by dividing each pixel by 255.0 \n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a52ae0",
   "metadata": {},
   "source": [
    "Comment on the importnace of adding augmented images to training data (be sure to justify why you don't augment the validation and test sets as well): [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffbd567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply data preprocessing\n",
    "X_train, y_train = data_preprocessing(X_train, y_train, data_partition='train')\n",
    "X_val, y_val = data_preprocessing(X_val, y_val, data_partition='val')\n",
    "X_test, y_test = data_preprocessing(X_test, y_test, data_partition='val')\n",
    "\n",
    "# print shapes\n",
    "print('Shape of train images ', X_train.shape)\n",
    "print('Shape of train labels ', y_train.shape)\n",
    "print('Shape of val images ', X_val.shape)\n",
    "print('Shape of test images ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c298b8b",
   "metadata": {},
   "source": [
    "Reshape training, val, and test data (to be compatible with sklearn Decision Forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349467a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of features (multiply RGB features)\n",
    "features_shape = X_train[:, :, :, 0].shape[1] * X_train.shape[2] * X_train.shape[3]\n",
    "print('Total number of features used for Decision Forests', features_shape)\n",
    "\n",
    "# reshape data\n",
    "X_train_re = X_train.reshape(X_train.shape[0], features_shape)\n",
    "X_val_re = X_val.reshape(X_val.shape[0], features_shape)\n",
    "X_test_re = X_test.reshape(X_test.shape[0], features_shape)\n",
    "\n",
    "# print shapes\n",
    "print('Shape of train images ', X_train_re.shape)\n",
    "print('Shape of train labels ', y_train.shape)\n",
    "print('Shape of val images ', X_val_re.shape)\n",
    "print('Shape of test images ', X_test_re.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fbfd69",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd93298",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 6 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcf13b",
   "metadata": {},
   "source": [
    "Implement a Decision Forest classifier according to the following guidelines (let's call this model our baseline classifier):\n",
    "    \n",
    "- Use the <span style=\"color:chocolate\">RandomForestClassifier</span> class available in the <span style=\"color:chocolate\">sklearn.ensemble</span> module;\n",
    "- Set the following argument values:\n",
    "    - n_estimators=2,\n",
    "    - n_jobs=1\n",
    "    - random_state=7\n",
    "    - max_depth=8\n",
    "- Train the model on (X_train_re, y_train) data;\n",
    "- Evaluate the accuracy of the model on (X_train_re, y_train) and (X_val_re, y_val) data. Comment on model performance on training vs. validation datasets. Does the model generalize well?\n",
    "- Plot the confusion matrix using (y_val, y_val_pred) data. Comment on the classes that the model confuses the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289348b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c9119",
   "metadata": {},
   "source": [
    "Comment on model accuracy on training vs. validation data: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79acca10",
   "metadata": {},
   "source": [
    "Does the model generalize well?: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5748c074",
   "metadata": {},
   "source": [
    "Comment on the classes that the model confuses the most: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa0e2c7",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 7 (20 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68a6af0",
   "metadata": {},
   "source": [
    "Implement a Decision Forest classifier that improves the validation set accuracy performance of the baseline model implemented above by at least 10% (the more you can improve the better). The model should also generalize well (the performance difference between the training and validation sets should be at most 10%). Also, be sure to follow these guidelines: \n",
    "    \n",
    "- Use the <span style=\"color:chocolate\">RandomForestClassifier</span> or the <span style=\"color:chocolate\">GradientBoostingClassifier</span> available in the <span style=\"color:chocolate\">sklearn.ensemble</span> module\n",
    "- Be explicit on how your implementation is different compared to the baseline classifier:\n",
    "    - different argment values for the baseline model (RandomForestClassifier)?\n",
    "    - different Decision Forest classifier?\n",
    "    - different data preprocessing procedure?\n",
    "    - a combination of the three points above\n",
    "    - anything else?\n",
    "- Train the model on (X_train_re, y_train) data.\n",
    "- Evaluate the model's accuracy on (X_val_re, y_val) data. Comment on training vs. validation performance relative to baseline model.\n",
    "- Does your model generalize well?\n",
    "- Plot confusion matrix using the (y_val, y_val_pred) data. Comment on the classes the model confuses the most relative to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363863b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf2 = ''\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e19ed7",
   "metadata": {},
   "source": [
    "How your implementation is different compared to the baseline classifier: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21201beb",
   "metadata": {},
   "source": [
    "Comment on training vs. validation performance relative to baseline model: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc14a47",
   "metadata": {},
   "source": [
    "Does the model generalize well? [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee10cf",
   "metadata": {},
   "source": [
    "Comment on the classes the model confuses the most relative to the baseline: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526a1c6",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Evaluation and Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd09178",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 8 (2 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff31fbc",
   "metadata": {},
   "source": [
    "Report accuracy performance on the test data using the model trained for Exercise 7. How does the test set performance compare with the one reported for the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cbbd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa803a7",
   "metadata": {},
   "source": [
    "Comment on test set accuracy vs. validation set accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab947f",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf04a06",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 9 (8 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ca925",
   "metadata": {},
   "source": [
    "Would you recommend a Decision Forest for land cover classification? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb37c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe2c657",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 10 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fedccf",
   "metadata": {},
   "source": [
    "What other ML model would you propose to improve performance over the Decision Forest classifier you implemented for Exercise 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56008384",
   "metadata": {},
   "source": [
    "---\n",
    "#### <span style=\"color:chocolate\"> Bonus question (20 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fca048",
   "metadata": {},
   "source": [
    "Implement the idea proposed for Exercise 10. Perform hyperparameter tuning using the training and validation sets, then report the model performance on the test data. Does your model generalize well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb763bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
