{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKsRDH5ZUdfasdv"
   },
   "source": [
    "# Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
    "\n",
    "Your work will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
    "\n",
    "Additional points may be deducted if these requirements are not met:\n",
    "    \n",
    "* Comment your code;\n",
    "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own;\n",
    "* Try and minimize the use of the global namespace (meaning, keep things inside functions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43534tdfgs-v"
   },
   "source": [
    "``Objectives``\n",
    "\n",
    "* This assignment connects all the pieces involved in training feed-forward fully connected neural networks (FFNN); \n",
    "\n",
    "* You will run a full set of experiments to explore different hyperparameters and hidden layer sizes for two datasets, and then document your findings.\n",
    "\n",
    "``Data``\n",
    "* Digits MNIST\n",
    "* Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7X58hOMTUH-w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style=\"darkgrid\")  # default style\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL5O-SOu7kYN"
   },
   "source": [
    "---\n",
    "### Step 1: Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST dataset.\n",
    "(X_train_fashion, Y_train_fashion), (X_test_fashion, Y_test_fashion) = fashion_mnist.load_data()\n",
    "\n",
    "# Load the Digits MNIST dataset.\n",
    "(X_train_digits, Y_train_digits), (X_test_digits, Y_test_digits) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Fashion MNIST``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 1733,
     "status": "ok",
     "timestamp": 1622667905055,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "load_auto_data_set_code",
    "outputId": "99d54f72-4abc-49f5-cdff-7d3833e3be50"
   },
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X_train_fashion = X_train_fashion / 255.\n",
    "X_test_fashion = X_test_fashion / 255.\n",
    "\n",
    "# Flatten Y_train and Y_test, so they become vectors of label values.\n",
    "Y_train_fashion = Y_train_fashion.flatten()\n",
    "Y_test_fashion = Y_test_fashion.flatten()\n",
    "\n",
    "label_names = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "               'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "# Apply random shufflying to training examples.\n",
    "np.random.seed(0)\n",
    "indices = np.arange(X_train_fashion.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "X_train_fashion = X_train_fashion[shuffled_indices]\n",
    "Y_train_fashion = Y_train_fashion[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND9b1ShF745M"
   },
   "source": [
    "``Digits MNIST``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1622667906354,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "ACD38quoz8D_",
    "outputId": "a294a8c6-de0a-421f-c17a-fe9ee1e79767"
   },
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X_train_digits = X_train_digits / 255\n",
    "X_test_digits = X_test_digits / 255\n",
    "\n",
    "# Flatten Y_train and Y_test, so they become vectors of label values.\n",
    "Y_train_digits = Y_train_digits.flatten()\n",
    "Y_test_digits = Y_test_digits.flatten()\n",
    "\n",
    "# Apply random shufflying to training examples.\n",
    "np.random.seed(0)\n",
    "indices = np.arange(X_train_digits.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "X_train_digits = X_train_digits[shuffled_indices]\n",
    "Y_train_digits = Y_train_digits[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 1:</span> Getting to know your data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following task:\n",
    "\n",
    "1. Show the first training example in X_train_fashion;\n",
    "2. Show the first training example in X_train_digits;\n",
    "3. Display the first 5 images in X_train_digits for each class in Y_train_digits, arranged in a 10x5 grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09EpBz1w0_Nj"
   },
   "source": [
    "### Step 4: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 2:</span> Define model (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWbRPrMyHZ2J"
   },
   "source": [
    "1. Fill in the <span style=\"color:chocolate\">build_model()</span> function below, including all the arguments listed in the function definition. Note: the activation function parameter is only for the the hidden layers; use the appropriate final classification function for the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GeBGPGhQ5bu"
   },
   "outputs": [],
   "source": [
    "def build_model(n_classes,\n",
    "                hidden_layer_sizes=[],\n",
    "                activation='relu',\n",
    "                optimizer='SGD',\n",
    "                learning_rate=0.01,\n",
    "                metric='metric'):\n",
    "    \"\"\"Build a multi-class logistic regression model using Keras.\n",
    "\n",
    "    Args:\n",
    "    n_classes: Number of output classes in the dataset.\n",
    "    hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "    activation: The activation function to use for the hidden layers.\n",
    "    optimizer: The optimizer to use (SGD, Adam).\n",
    "    learning_rate: The desired learning rate for the optimizer.\n",
    "    metric: The desired metric.\n",
    "\n",
    "    Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    model = NotImplemented\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYpd5gUeH9pn"
   },
   "source": [
    "You can now run a suite of experiments to see how the hyperparameters and layer sizes effect model performance. \n",
    "\n",
    "The <span style=\"color:chocolate\">train_and_evaluate()</span> function below can be used to run experiments and retrieve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 22089,
     "status": "ok",
     "timestamp": 1622667987968,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "OKeyZXLJJlA4",
    "outputId": "c3dd339a-443d-4830-ece9-adb2873ed629"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(data='digits',\n",
    "                       hidden_layer_sizes=[],\n",
    "                       activation='tanh',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       metric='accuracy',\n",
    "                       num_epochs=10):\n",
    "\n",
    "  # Build the model.\n",
    "    model = build_model(n_classes=10,\n",
    "                      hidden_layer_sizes=hidden_layer_sizes,\n",
    "                      activation=activation,\n",
    "                      optimizer=optimizer,\n",
    "                      metric=metric,\n",
    "                      learning_rate=learning_rate)\n",
    "\n",
    "  # Select the dataset.\n",
    "    if data == 'digits':\n",
    "        X_train = X_train_digits\n",
    "        X_test = X_test_digits\n",
    "        Y_train = Y_train_digits\n",
    "        Y_test = Y_test_digits\n",
    "    \n",
    "    elif data == 'fashion':\n",
    "        X_train = X_train_fashion\n",
    "        X_test = X_test_fashion\n",
    "        Y_train = Y_train_fashion\n",
    "        Y_test = Y_test_fashion\n",
    "    else:\n",
    "        raise 'Unsupported dataset: %s' %data\n",
    "\n",
    "  # Train the model.\n",
    "    print('Training the', data, 'model...')\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=64,\n",
    "        validation_split=0.1,\n",
    "        verbose=0)\n",
    "\n",
    "    # Retrieve the training metrics (after each train epoch) and the final validation\n",
    "    # accuracy.\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    plt.plot(train_accuracy, label='train_accuracy')\n",
    "    plt.plot(val_accuracy, label='validation accuracy')\n",
    "    plt.xticks(range(num_epochs))\n",
    "    plt.xlabel('Train epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print('Training accuracy: %1.4f' %train_accuracy[-1])\n",
    "    print('Validation accuracy: %1.4f' %val_accuracy[-1])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# run the function\n",
    "model = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0Ewe-W8IT-J"
   },
   "source": [
    "### <span style=\"color:chocolate\">Exercise 3:</span> Ablation study (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Conduct experiments and record the training and validation set accuracy results in the table below. You may extend the table for additional experiments as needed.\n",
    "2. Report the hyperparameter values for your preferred architecture configuration.\n",
    "3. Run the model once more using your preferred hyperparameter configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_ddqOToQ6WW"
   },
   "source": [
    "Data | Hidden sizes | Activation| Optimizer | Learning rate | #Parameters | Training accuracy| Validation accuracy\n",
    "-|-|-|-|-|-|-|-\n",
    " digits | [] | tanh | SGD |0.01| 7850 | |\n",
    " digits | [] | relu | SGD |0.01| 7850 | |\n",
    " digits | [] | relu | Adam |0.01| 7850 | |\n",
    " digits | [128] | relu | Adam |0.01| 101770 | |\n",
    " digits | [256, 128] | relu | Adam |0.01| 235146 | |\n",
    "-|-|-|-|-|-|-|-\n",
    " fashion | [] | tanh | SGD |0.01| 7850 | |\n",
    " fashion | [] | relu | SGD |0.01| 7850 | |\n",
    " fashion | [] | relu | Adam |0.01| 7850 | |\n",
    " fashion | [128] | relu | Adam |0.01| 101770 | |\n",
    " fashion | [256, 128] | relu | Adam |0.01| 235146 | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Evaluation and Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 4:</span> Compute metrics (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've determined the optimal set of hyperparameters, it's time to evaluate your optimized model on the test data to gauge its performance in real-world scenarios, commonly known as inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate accuracy on both train and test datasets. Note: you will need to convert the vector of predicted probabilities to a class label using the argmax operation. Hint: You can utilize the <span style=\"color:chocolate\">model.predict()</span> method provided by tf.keras and the <span style=\"color:chocolate\">np.max()</span> method available in NumPy; or you can use the <span style=\"color:chocolate\">model.evaluare()</span> method provided by tf.keras directly.\n",
    "\n",
    "2. Does the model demonstrate strong generalization capabilities? Provide an explanation based on your accuracy observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMlQhpKHdte3dv5Jw16gtIs",
   "collapsed_sections": [],
   "name": "06 Neural Networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
