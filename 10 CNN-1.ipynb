{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
    "\n",
    "Your work will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
    "\n",
    "Additional points may be deducted if these requirements are not met:\n",
    "    \n",
    "* Comment your code;\n",
    "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own;\n",
    "* Try and minimize the use of the global namespace (meaning, keep things inside functions).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``Objectives``\n",
    "1. Implement a CNN to detect diabetic retinopathy (DR) from retina images taken using fundus photography under a variety of imaging conditions.\n",
    "2. Improve generalization performance and reduce overfitting using **image transformation** and **data augmentation** techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``Motivation``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diabetic retinopathy (DR) is an eye condition that  affects blood vessels in the retina. It can cause vision loss and blindness in people who have diabetes. Screening for DR allows earlier and more effective treatment options for millions of people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ``Data``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will use a small dataset of retina images (`Download` links: [images](https://drive.google.com/drive/folders/1sdfUC64Un1iwuiHEehcbijxB54OhU_nd?usp=sharing) and [labels](https://drive.google.com/drive/folders/1MOlSJBZg7L1HtG5vHPt77ighRvQaGfDg?usp=sharing)). You will **build** and **train** a **CNN model** to predict whether or not to refer a patient for DR treatment using binarized severity of DR in patients: no referral if {No DR, mild} and referral if {moderate, severe, and proliferate DR}.\n",
    "\n",
    "\n",
    "<u>Note</u>: the original dataset is hosted by Kaggle [[Source]](https://www.kaggle.com/c/aptos2019-blindness-detection/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and make sure to replace IMAGE_PATH and LABEL_PATH with the path to the directories where you saved the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# tf and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(2)\n",
    "%matplotlib inline\n",
    "\n",
    "# FILL IN CODE HERE #\n",
    "IMAGE_PATH = './DiabeticRetinopathy/images/' # replace with your path\n",
    "LABEL_PATH = './DiabeticRetinopathy/labels/' # replace with your path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you may ask yourself what the best model that fits this data is. First, you will want to read through the data description in Kaggle (see the link to the original dataset above). Understanding what you are working with challenges you to write preprocessing code that uncovers your data's most helpful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <span style=\"color:chocolate\"> Exercise 1 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data description from Kaggle and list (a) the source of images and (b) the labeling procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Written answer*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the 2D images and their corresponding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``labels``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\n",
    "    LABEL_PATH + 'labels.csv'\n",
    ")\n",
    "\n",
    "print('Shape of labels:', labels.shape)\n",
    "print('Unique diagnosis codes:', np.sort(labels.diagnosis.unique()))\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 200 training images corrresponding to 5 different diabetic retinopathy (DR) diagnosis codes: \n",
    "\n",
    "* No DR (0)\n",
    "* mild (1)\n",
    "* moderate (2)\n",
    "* severe (3)\n",
    "* proliferate DR (4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``images``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for idx, img in enumerate(os.listdir(IMAGE_PATH)):\n",
    "    img = load_img(\n",
    "    IMAGE_PATH + img)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 2 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram for the five classes of DR. Are the classes balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on class balance: [YOUR ANSWER HERE]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 3 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print 8 images from the data. What can you say about the size, focus/orientation of these images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the size, focus/orientation of the 8 images: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will correct for class imbalance. Note that imbalanced data is common in healthcare, and it happens because some diseases are rare. The presence of imbalanced data hampers the detection of rare events as most classification methods implicitly assume a similar occurrence of classes and are designed to maximize the overall classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will correct for class imbalance in two ways:\n",
    "\n",
    "  * First, we will binarize the DR diagnosis as follows:\n",
    "     - 'no refer' are {No DR, mild}\n",
    "     - 'refer' are {Moderate, Severe, Proliferate}\n",
    "\n",
    "\n",
    "  * Second, we'll only take 80 random samples from the 'no refer' class and 80 from the 'refer' class.\n",
    "\n",
    "It is a crude method to deal with imbalanced data, but it will be good enough for this homework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "no_refer = labels[labels.diagnosis.isin((0,1))]\n",
    "refer = labels[labels.diagnosis.isin((2,3,4))]\n",
    "\n",
    "# randomly draw 80 images from each classes\n",
    "temp_no_refer = list(np.random.choice(\n",
    "    no_refer.id_code,\n",
    "    size=80,\n",
    "    replace=False\n",
    "))\n",
    "\n",
    "temp_refer = list(np.random.choice(\n",
    "    refer.id_code,\n",
    "    size=80,\n",
    "    replace=False\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the ``preprocess_data_part1()`` function defined below to generate lists of images and labels (images_mini and y_mini) based on the values in the temp_no_refer and temp_refer lists. Note that the size of the image is set to (224, 224)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_part1(IMAGE_PATH, LABEL_PATH, temp_no_refer, temp_refer):\n",
    "    \"\"\" Generate lists of images and labelsbased on temp_no_refer and temp_refer lists\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    IMAGE_PATH (str): path to directory with images.\n",
    "    LABEL_PATH (str): path to directory with labels.\n",
    "    temp_no_refer (str): list of labels for the no refer category\n",
    "    temp_refer (str): list of labels for the refer category\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    images_mini  (np.ndarray): Images of shape (N, 224, 224, 3)\n",
    "    y_mini (np.ndarray): Labels of shape (N,)    \n",
    "    \"\"\"\n",
    "    y_mini = []\n",
    "    images_mini = []\n",
    "\n",
    "    # create lists of images and labels `images_mini` and `y_mini` \n",
    "    # based on temp_no_refer and temp_refer selections\n",
    "    for idx, img in enumerate(os.listdir(IMAGE_PATH)):\n",
    "        # read labels\n",
    "        if img.split('.')[0] in temp_no_refer:\n",
    "                y_mini.append(0)\n",
    "        elif img.split('.')[0] in temp_refer:\n",
    "                y_mini.append(1)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # read image\n",
    "        img = load_img(\n",
    "            IMAGE_PATH + img,\n",
    "            target_size=(224, 224)\n",
    "        )\n",
    "        \n",
    "        # transform image to array\n",
    "        img = img_to_array(img)\n",
    "\n",
    "        # append to images\n",
    "        images_mini.append(img)\n",
    "\n",
    "    # stack images and trasnform to array\n",
    "    images_mini = np.stack(images_mini)\n",
    "    y_mini = np.array(y_mini).flatten() \n",
    "    \n",
    "    return images_mini, y_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate images and labels based on preprocess_data_part1() function\n",
    "images_mini, y_mini = preprocess_data_part1(\n",
    "    IMAGE_PATH, LABEL_PATH, temp_no_refer, temp_refer\n",
    ")\n",
    "\n",
    "print(f\"images_mini shape {images_mini.shape}\")\n",
    "print(f\"y_mini shape {y_mini.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 4 (20 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, validation, and test data. Implement the `preprocess_data_part2()` function according to the following guidelines:\n",
    "\n",
    "1. shuffle images and labels before splitting the data\n",
    "\n",
    "2. use a (0.6,0.2,0.2)train/validation/test set split\n",
    "\n",
    "3. perform image transformation and augmentation, as follows:\n",
    "    * Applied on training set only:\n",
    "         - create additional copies (augmentations) of the training images by flipping left right each image (Hint: use the method available in the tf.image module).\n",
    "         - concatenate the augmented images to the original training images. Note that the train set should be double in size after data augmentation, i.e., 192 images and labels.\n",
    "    * Applied on training, validation, and test sets:\n",
    "        - rescale images by dividing each pixel by 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason for doing image augmentation: The quantity and diversity of data gathered significantly impact the results of a CNN model. One can use augmentations to artificially inflate the training dataset by warping the original data so that their label does not change. These augmentations can significantly improve learning results without collecting new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_part2(images, labels, splits):\n",
    "    \"\"\" Split data into train, validation and test sets; apply transformaions and augmentations\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    images  (np.ndarray): Images of shape (N, 224, 224, 3)\n",
    "    labels (np.ndarray): Labels of shape (N,)   \n",
    "    splits (tuple): 3 values summing to 1 defining split of train, validation and test sets\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_train (np.ndarray): Train images of shape (N_train, 224, 224, 3)\n",
    "    y_train (np.ndarray): Train labels of shape (N_train,)\n",
    "    X_val (np.ndarray): Val images of shape (N_val, 224, 224, 3)\n",
    "    y_val (np.ndarray): Val labels of shape (N_val,)\n",
    "    X_test (np.ndarray): Test images of shape (N_test, 224, 224, 3)\n",
    "    y_test (np.ndarray): Test labels of shape (N_test,)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # NOTE: Each time you run this cell, you'll re-shuffle the data. The ordering will be the same due to the random seed generator \n",
    "    tf.random.set_seed(1234)\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    # shuffle data\n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    # create data splits (training, val, and test sets)\n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    # image augmentation (random flip) on training data\n",
    "    X_train_augm = '' # FILL IN CODE HERE #\n",
    "\n",
    "    # concatenate original X_train and augmented X_train_augm data\n",
    "    X_train = '' # FILL IN CODE HERE #\n",
    "\n",
    "    # concatenate y_train (note the label is preserved)\n",
    "    y_train_augm = y_train\n",
    "    y_train = tf.concat([y_train, y_train_augm],axis=0)\n",
    "\n",
    "    # shuffle X_train and y_train, i.e., shuffle two tensors in the same order\n",
    "    shuffle = tf.random.shuffle(tf.range(tf.shape(X_train)[0], dtype=tf.int32))\n",
    "    X_train = tf.gather(X_train, shuffle).numpy() # transform X back to numpy array instead of tensor\n",
    "    y_train = tf.gather(y_train, shuffle).numpy() # transform y back to numpy array instead of tensor\n",
    "\n",
    "    # rescale training, val, and test images by dividing each pixel by 255.0 \n",
    "    # FILL IN CODE HERE #\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define splits\n",
    "split = (0.6, 0.2, 0.2)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data_part2(\n",
    "    images_mini,\n",
    "    y_mini,\n",
    "    split\n",
    ")\n",
    "\n",
    "print(f\"X_train shape {X_train.shape}\")\n",
    "print(f\"y_train shape {y_train.shape}\")\n",
    "print(f\"X_val shape {X_val.shape}\")\n",
    "print(f\"y_val shape {y_val.shape}\")\n",
    "print(f\"X_test shape {X_test.shape}\")\n",
    "print(f\"y_test shape {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 5 (20 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to build and train a CNN model to refer patients to doctors based on the severity of DR seen in these images. You are interested in exploring binary classification of 'no refer' and 'refer'.\n",
    "\n",
    "Implement a CNN classifier according to the following guidelines (let's call this model1; this model will serve as our baseline classifier):\n",
    "\n",
    "1. Implement this model using the TF Keras API.\n",
    "1. The model receives input images of size 224 x 224 x 3 (that is, the images have three color channels)\n",
    "2. The input data goes through one convolutional layer that has the following specifications:\n",
    "    - filters = 12\n",
    "    - kernel_size = (4 x 4)\n",
    "    - strides = (1, 1)\n",
    "    - padding = 'same'\n",
    "    - data_format = 'channels_last'\n",
    "    - name = 'conv_1'\n",
    "    - activation = 'relu'\n",
    "3. The convolutional layer is followed by a max-pooling layer with pool_size = (2,2). Note: this will reduce the size of the feature maps.\n",
    "4. The max-pooling layer is followed by a dropout layer with rate = 0.3.\n",
    "5. The dropout layer is followed by a flattening layer.\n",
    "6. The last layer of the model is the classification head.\n",
    "7. Build and compile the model using the Adam optimizer and learning_rate = 0.1. Print summary of the model.\n",
    "8. Train the model on (X_train, y_train) data for 20 epochs. Add early stopping (Hint: pass the early_stopping implementation below to the fit() method as \"callbacks=[early_stopping]\").\n",
    "9. How many parameters does the model have?\n",
    "10. Evaluate the accuracy of the model on (X_train, y_train) and (X_val, y_val) data. Comment on model performance on training vs. validation datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an instance of the early_stopping class\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "monitor='accuracy', \n",
    "verbose=1,\n",
    "patience=4,\n",
    "mode='max',\n",
    "restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# initialize model\n",
    "model1 = tf.keras.Sequential()\n",
    "\n",
    "# add convolutional layer to model1\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# add max pooling layer to model1\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# add dropout layer to model1\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# add a flattening layer to model1\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# add the classification layer to model1\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# build and compile model1\n",
    "model1.build(input_shape=(None, 224, 224, 3))\n",
    "model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# print model1 summary\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# train model1 on (X_train, y_train) data\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# evaluate the accuracy of model1 on (X_train, y_train) and (X_val, y_val)\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many parameters does model1 have? [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on model1 accuracy on training vs. validation data: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 6 (20 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will build a model with a more complex CNN architecture than the baseline CNN classifier above. Your tasks are as follows:\n",
    "\n",
    "1. Implement this more complex CNN model (call this model2). Note that you are free to experiment with the number of hidden convolutional layers and hyperparameter values. The only requirement is that the minimum number of parameters be greater than 1M.\n",
    "2. Explain how your implementation differs from the baseline CNN classifier.\n",
    "3. Train the model on (X_train, y_train) data for 20 epochs. Add early stopping (Hint: pass the early_stopping implementation above to the fit() method as \"callbacks=[early_stopping]\").\n",
    "4. How many parameters does the model have?\n",
    "5. Evaluate the accuracy of the model on (X_train, y_train) and (X_val, y_val) data. Comment on model performance on training vs. validation performance relative to the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many parameters does model2 have? [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on model2 performance on training vs. validation performance relative to the baseline model: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:chocolate\"> Exercise 7 (10 points) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now use the test data to evaluate the performance (accuracy) of model1 and model2 on unseen data. Which model performs best? Is this result expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model performs best? [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this result expected? [YOUR ANSWER HERE]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
